{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2유형 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아답터 2유형 풀이\n",
    "- https://www.youtube.com/watch?v=QtWhHCuVIxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력을 원하실 경우 print() 함수 활용\n",
    "# 예시) print(df.head())\n",
    "\n",
    "# getcwd(), chdir() 등 작업 폴더 설정 불필요\n",
    "# 파일 경로 상 내부 드라이브 경로(C: 등) 접근 불가\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/customer_train.csv\")\n",
    "test = pd.read_csv(\"data/customer_test.csv\")\n",
    "\n",
    "# 사용자 코딩\n",
    "# 빅데이터 실기 예제 : 예측 총 구매금액\n",
    "\n",
    "# 전처리\n",
    "X = train.drop(['총구매액'], axis = 1)\n",
    "y = train['총구매액']\n",
    "\n",
    "X_full = pd.concat([X, test], axis=0)\n",
    "X_full = X_full.drop(['회원ID'], axis=1)\n",
    "\n",
    "print(X_full.shape)\n",
    "\n",
    "# 결측치 처리\n",
    "X_full['환불금액'] = X_full['환불금액'].fillna(0)\n",
    "\n",
    "# 랜덤포레스트의 경우 생략함\n",
    "\n",
    "# 범주형 변수 인코딩 시 get_dummies\n",
    "X_full = pd.get_dummies(X_full)\n",
    "print(X_full.shape)\n",
    "\n",
    "# 데이터 분리\n",
    "X_train = X_full[:train.shape[0]]\n",
    "X_test = X_full[train.shape[0]:]\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 모델 학습 및 검증\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# 평가\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "rmse = root_mean_squared_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "print(rmse, r2)\n",
    "\n",
    "# 결과\n",
    "y_pred = model.predict(X_test)\n",
    "result = pd.DataFrame(y_pred, columns = ['pred'])\n",
    "result.to_csv('result.csv', index=False)\n",
    "\n",
    "result = pd.read_csv('result.csv')\n",
    "print(result)\n",
    "# 답안 제출 참고\n",
    "# 아래 코드는 예시이며 변수명 등 개인별로 변경하여 활용\n",
    "# pd.DataFrame변수.to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퇴근후딴짓 2유형 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력을 원하실 경우 print() 함수 활용\n",
    "# 예시) print(df.head())\n",
    "\n",
    "# getcwd(), chdir() 등 작업 폴더 설정 불필요\n",
    "# 파일 경로 상 내부 드라이브 경로(C: 등) 접근 불가\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/customer_train.csv\")\n",
    "test = pd.read_csv(\"data/customer_test.csv\")\n",
    "\n",
    "# 사용자 코딩\n",
    "# 빅데이터 실기 예제 : 예측 총 구매금액\n",
    "\n",
    "# EDA\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# 전처리\n",
    "target =train.pop('총구매액')\n",
    "train['환불금액'] = train['환불금액'].fillna(0)\n",
    "test['환불금액'] = test['환불금액'].fillna(0)\n",
    "\n",
    "# 선택 1. 레이블 인코딩, train 주구매상품이 test 주구매상품을 포함하기 때문에 합칠 필요는 없음\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ['주구매상품', '주구매지점']\n",
    "for col in cols:\n",
    "\tle = LabelEncoder()\n",
    "\ttrain[col] = le.fit_transform(train[col])\n",
    "\ttest[col] = le.transform(test[col])\n",
    "\t\n",
    "\t\n",
    "# 선택 2. 원핫인코딩. 만약 카테고리가 다르면 합쳐서 진행이 필요함 => 그냥 일단 이걸로 한 다음에 에러가 나면 선택 1을 하는 방법\n",
    "# df = pd.concat([train, test])\n",
    "# df = pd.get_dummies(df)\n",
    "\n",
    "# # concat을 사용하면 다시 분리해주어야함\n",
    "# train = df.iloc[:len(train)]\n",
    "# test = df.iloc[len(train):]\n",
    "# print(train.shape, test.shape)\n",
    "\n",
    "# 검증용 데이터\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size = 0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 모델 학습및평가\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "print(\"rmse:\", root_mean_squared_error(y_val, pred))\n",
    "print(\"r2:\", r2_score(y_val, pred))\n",
    "\n",
    "# 제출\n",
    "pred = model.predict(test)\n",
    "submit = pd.DataFrame({'pred':pred})\n",
    "submit.to_csv('result.csv', index=False)\n",
    "print(pd.read_csv('result.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블 인코딩, 원핫인코딩 예측 값이 계속 바뀜..머임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 환자의 당뇨병 여부 예층\n",
    "- 예측할 컬럼: Outcome 0: 정상, 1: 당뇨병\n",
    "- 성능은 ROC-AUC 평가지표에 따라 채점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/diabetes_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/diabetes_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (614, 9)\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            1      118             58             36       94  33.3   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.261   23        0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               614 non-null    int64  \n",
      " 1   Glucose                   614 non-null    int64  \n",
      " 2   BloodPressure             614 non-null    int64  \n",
      " 3   SkinThickness             614 non-null    int64  \n",
      " 4   Insulin                   614 non-null    int64  \n",
      " 5   BMI                       614 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  614 non-null    float64\n",
      " 7   Age                       614 non-null    int64  \n",
      " 8   Outcome                   614 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 43.3 KB\n",
      "None\n",
      "결측치\n",
      "0\n",
      "test: (154, 8)\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            3      102             74              0        0  29.5   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.121   32  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               154 non-null    int64  \n",
      " 1   Glucose                   154 non-null    int64  \n",
      " 2   BloodPressure             154 non-null    int64  \n",
      " 3   SkinThickness             154 non-null    int64  \n",
      " 4   Insulin                   154 non-null    int64  \n",
      " 5   BMI                       154 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  154 non-null    float64\n",
      " 7   Age                       154 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 9.8 KB\n",
      "None\n",
      "결측치\n",
      "0\n",
      "==tartget 빈도==\n",
      "0    403\n",
      "1    211\n",
      "Name: Outcome, dtype: int64\n",
      "==분할된 데이터 크기==\n",
      "(491, 8) (123, 8) (491,) (123,)\n",
      "예측: [[0.79013973 0.20986027]\n",
      " [0.27405468 0.72594532]\n",
      " [0.53279236 0.46720764]\n",
      " [0.68700178 0.31299822]\n",
      " [0.82397826 0.17602174]]\n",
      "roc-auc: 0.8246575342465753\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.253687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred\n",
       "0  0.183228\n",
       "1  0.253687\n",
       "2  0.146948\n",
       "3  0.060001\n",
       "4  0.075731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 탐색적 분석\n",
    "print(\"train:\", train.shape)\n",
    "print(train.head(1))\n",
    "print(train.info())\n",
    "\n",
    "print('결측치')\n",
    "print(train.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"test:\", test.shape)\n",
    "print(test.head(1))\n",
    "print(test.info())\n",
    "\n",
    "print('결측치')\n",
    "print(test.isnull().sum().sum())\n",
    "\n",
    "print('==tartget 빈도==')\n",
    "print(train['Outcome'].value_counts())\n",
    "\n",
    "# 전처리\n",
    "target = train.pop('Outcome')\n",
    "\n",
    "# 검증 데이터 나누기\n",
    "# 모두 수치형 데이터고 결측치가 없어서 따로 레이블 인코딩이나 원핫인코딩을 하지 않음\n",
    "# 모두 수치형 데이터라면 스케일링을 해줄 수 있음\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val =  train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print('==분할된 데이터 크기==')\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=0, max_depth = 5, n_estimators=500)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict_proba(X_val) # roc_auc_score는 확률기반이므로 predict_proba를 써야함\n",
    "print(\"예측:\", pred[:5])\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_val, pred[:,1])\n",
    "print('roc-auc:', roc_auc)\n",
    "\n",
    "pred = model.predict_proba(test)\n",
    "submit = pd.DataFrame({\n",
    "    'pred': pred[:,1]\n",
    "})\n",
    "submit.head(5)\n",
    "\n",
    "# submit.to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 이직 여부 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15326 entries, 0 to 15325\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             15326 non-null  int64  \n",
      " 1   city                    15326 non-null  object \n",
      " 2   city_development_index  15326 non-null  float64\n",
      " 3   gender                  11750 non-null  object \n",
      " 4   relevent_experience     15326 non-null  object \n",
      " 5   enrolled_university     15012 non-null  object \n",
      " 6   education_level         14961 non-null  object \n",
      " 7   major_discipline        13045 non-null  object \n",
      " 8   experience              15272 non-null  object \n",
      " 9   company_size            10539 non-null  object \n",
      " 10  company_type            10383 non-null  object \n",
      " 11  last_new_job            14984 non-null  object \n",
      " 12  training_hours          15326 non-null  int64  \n",
      " 13  target                  15326 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3832 entries, 0 to 3831\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             3832 non-null   int64  \n",
      " 1   city                    3832 non-null   object \n",
      " 2   city_development_index  3832 non-null   float64\n",
      " 3   gender                  2900 non-null   object \n",
      " 4   relevent_experience     3832 non-null   object \n",
      " 5   enrolled_university     3760 non-null   object \n",
      " 6   education_level         3737 non-null   object \n",
      " 7   major_discipline        3300 non-null   object \n",
      " 8   experience              3821 non-null   object \n",
      " 9   company_size            2681 non-null   object \n",
      " 10  company_type            2635 non-null   object \n",
      " 11  last_new_job            3751 non-null   object \n",
      " 12  training_hours          3832 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 389.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id               15326\n",
       "city                        123\n",
       "city_development_index       93\n",
       "gender                        3\n",
       "relevent_experience           2\n",
       "enrolled_university           3\n",
       "education_level               5\n",
       "major_discipline              6\n",
       "experience                   22\n",
       "company_size                  8\n",
       "company_type                  6\n",
       "last_new_job                  6\n",
       "training_hours              241\n",
       "target                        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target을 맞추어야함. 범주형 데이터가 10개. 수치형은 4개. 결측치도 존재함\n",
    "# 카테고리별 수량을 세보기 nunique()\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id               3832\n",
       "city                       113\n",
       "city_development_index      87\n",
       "gender                       3\n",
       "relevent_experience          2\n",
       "enrolled_university          3\n",
       "education_level              5\n",
       "major_discipline             6\n",
       "experience                  22\n",
       "company_size                 8\n",
       "company_type                 6\n",
       "last_new_job                 6\n",
       "training_hours             235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65 0.35]\n",
      " [0.33 0.67]\n",
      " [0.74 0.26]\n",
      " ...\n",
      " [0.54 0.46]\n",
      " [0.96 0.04]\n",
      " [0.45 0.55]]\n",
      "roc_auc: 0.7724341640093463\n",
      "   pred\n",
      "0  0.22\n",
      "1  0.43\n",
      "2  0.54\n"
     ]
    }
   ],
   "source": [
    "# 범주형이 있고, 컬럼의 수가 다르므로 train과 test를 합쳐서 원핫인코딩을 진행하고, 다시 train과 test로 나누기\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/hr_test.csv\")\n",
    "target=train.pop('target')\n",
    "# 결측치 처리\n",
    "train = train.fillna('X')\n",
    "test = test.fillna('X')\n",
    "\n",
    "# 원핫인코딩\n",
    "full = pd.concat([train, test])\n",
    "full_dummies = pd.get_dummies(full)\n",
    "\n",
    "n_train = len(train)\n",
    "\n",
    "train = full_dummies[:n_train]\n",
    "test = full_dummies[n_train:]\n",
    "\n",
    "# 검증 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "# 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict_proba(X_val)\n",
    "print(pred)\n",
    "# roc-auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_val, pred[:,1]) # proba를 쓰면 확률이라서 컬럼이 2개 생김김\n",
    "print('roc_auc:', roc_auc)\n",
    "\n",
    "# 결과 \n",
    "pred = model.predict_proba(test)\n",
    "submit = pd.DataFrame({\n",
    "    'pred':pred[:,1]\n",
    "})\n",
    "print(submit.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신용카드 신청자의 미래 신용 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 할때 결측치, 수치형/범주형, 데이터 불균형을 체크해야함\n",
    "# F1 평가지표에 따라 채점점\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/creditcard_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/creditcard_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25519 entries, 0 to 25518\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   25519 non-null  int64  \n",
      " 1   CODE_GENDER          25519 non-null  object \n",
      " 2   FLAG_OWN_CAR         25519 non-null  object \n",
      " 3   FLAG_OWN_REALTY      25519 non-null  object \n",
      " 4   CNT_CHILDREN         25519 non-null  int64  \n",
      " 5   AMT_INCOME_TOTAL     25519 non-null  float64\n",
      " 6   NAME_INCOME_TYPE     25519 non-null  object \n",
      " 7   NAME_EDUCATION_TYPE  25519 non-null  object \n",
      " 8   NAME_FAMILY_STATUS   25519 non-null  object \n",
      " 9   NAME_HOUSING_TYPE    25519 non-null  object \n",
      " 10  DAYS_BIRTH           25519 non-null  int64  \n",
      " 11  DAYS_EMPLOYED        25519 non-null  int64  \n",
      " 12  FLAG_MOBIL           25519 non-null  int64  \n",
      " 13  FLAG_WORK_PHONE      25519 non-null  int64  \n",
      " 14  FLAG_PHONE           25519 non-null  int64  \n",
      " 15  FLAG_EMAIL           25519 non-null  int64  \n",
      " 16  OCCUPATION_TYPE      17543 non-null  object \n",
      " 17  CNT_FAM_MEMBERS      25519 non-null  float64\n",
      " 18  STATUS               25519 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7591 entries, 0 to 7590\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   7591 non-null   int64  \n",
      " 1   CODE_GENDER          7591 non-null   object \n",
      " 2   FLAG_OWN_CAR         7591 non-null   object \n",
      " 3   FLAG_OWN_REALTY      7591 non-null   object \n",
      " 4   CNT_CHILDREN         7591 non-null   int64  \n",
      " 5   AMT_INCOME_TOTAL     7591 non-null   float64\n",
      " 6   NAME_INCOME_TYPE     7591 non-null   object \n",
      " 7   NAME_EDUCATION_TYPE  7591 non-null   object \n",
      " 8   NAME_FAMILY_STATUS   7591 non-null   object \n",
      " 9   NAME_HOUSING_TYPE    7591 non-null   object \n",
      " 10  DAYS_BIRTH           7591 non-null   int64  \n",
      " 11  DAYS_EMPLOYED        7591 non-null   int64  \n",
      " 12  FLAG_MOBIL           7591 non-null   int64  \n",
      " 13  FLAG_WORK_PHONE      7591 non-null   int64  \n",
      " 14  FLAG_PHONE           7591 non-null   int64  \n",
      " 15  FLAG_EMAIL           7591 non-null   int64  \n",
      " 16  OCCUPATION_TYPE      7591 non-null   object \n",
      " 17  CNT_FAM_MEMBERS      7591 non-null   float64\n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'RocCurveDisplay',\n",
       " 'SCORERS',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'plot_confusion_matrix',\n",
       " 'plot_precision_recall_curve',\n",
       " 'plot_roc_curve',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25085\n",
       "1      434\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER 카테고리 동일함\n",
      "FLAG_OWN_CAR 카테고리 동일함\n",
      "FLAG_OWN_REALTY 카테고리 동일함\n",
      "NAME_INCOME_TYPE 카테고리 동일함\n",
      "NAME_EDUCATION_TYPE 카테고리 동일함\n",
      "NAME_FAMILY_STATUS 카테고리 동일함\n",
      "NAME_HOUSING_TYPE 카테고리 동일함\n",
      "OCCUPATION_TYPE !!! 카테고리 동일하지 않음\n"
     ]
    }
   ],
   "source": [
    "# 범주형에서 카테고리가 다르면 삭제해야하나? 성능을 위해서 삭제하는건가?\n",
    "# 상관안쓰려면 원핫인코딩이 제일 편함\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "for col in cols:\n",
    "    set_train=set(train[col])\n",
    "    set_test = set(test[col])\n",
    "    if set_train == set_test:\n",
    "        print(col, '카테고리 동일함')\n",
    "    else:\n",
    "        print(col, '!!! 카테고리 동일하지 않음')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25519, 55) (7591, 55)\n",
      "0.2758620689655172\n"
     ]
    }
   ],
   "source": [
    "# 굳이 삭제 안해도 가능한 것 같음. 한번 테스트해보기\n",
    "# EDA 할때 결측치, 수치형/범주형, 데이터 불균형을 체크해야함\n",
    "# F1 평가지표에 따라 채점점\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/creditcard_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch6/creditcard_test.csv\")\n",
    "\n",
    "target = train.pop('STATUS')\n",
    "\n",
    "# 범주형이 있으므로 원핫인코딩\n",
    "# pd.get_dummies\n",
    "# 합쳤다가 다시 쪼개기\n",
    "full = pd.concat([train, test])\n",
    "full_dummies = pd.get_dummies(full)\n",
    "n_train = len(train)\n",
    "train = full_dummies[:n_train]\n",
    "test = full_dummies[n_train:]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 200)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "# F1 평가\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_val, pred))\n",
    "\n",
    "# 저장\n",
    "pred = model.predict(test)\n",
    "submit = pd.DataFrame({'pred':pred})\n",
    "#submit.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신용 등급 예층\n",
    "- f1-macro 지표에 따라 채점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 문제정의\n",
    "# 평가: f1 macro\n",
    "# target: Credit_Score\n",
    "# 최종파일: result.csv(컬럼 1개 pred)\n",
    "\n",
    "# 2. 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# train = pd.read_csv(\"score_train.csv\")\n",
    "# test = pd.read_csv(\"score_test.csv\")\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4198, 21)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4198 entries, 0 to 4197\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Delay_from_due_date       4198 non-null   float64\n",
      " 1   Num_of_Delayed_Payment    4198 non-null   float64\n",
      " 2   Num_Credit_Inquiries      4198 non-null   float64\n",
      " 3   Credit_Utilization_Ratio  4198 non-null   float64\n",
      " 4   Credit_History_Age        4198 non-null   float64\n",
      " 5   Payment_of_Min_Amount     4198 non-null   object \n",
      " 6   Amount_invested_monthly   4198 non-null   float64\n",
      " 7   Monthly_Balance           4198 non-null   float64\n",
      " 8   Credit_Mix                4198 non-null   object \n",
      " 9   Payment_Behaviour         4198 non-null   object \n",
      " 10  Age                       4198 non-null   float64\n",
      " 11  Annual_Income             4198 non-null   float64\n",
      " 12  Num_Bank_Accounts         4198 non-null   float64\n",
      " 13  Num_Credit_Card           4198 non-null   float64\n",
      " 14  Interest_Rate             4198 non-null   float64\n",
      " 15  Num_of_Loan               4198 non-null   float64\n",
      " 16  Monthly_Inhand_Salary     4198 non-null   float64\n",
      " 17  Changed_Credit_Limit      4198 non-null   float64\n",
      " 18  Outstanding_Debt          4198 non-null   float64\n",
      " 19  Total_EMI_per_month       4198 non-null   float64\n",
      " 20  Credit_Score              4198 non-null   object \n",
      "dtypes: float64(17), object(4)\n",
      "memory usage: 688.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6958813106865384\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/score_test.csv\")\n",
    "# target의 Credit_Score 인데 object임. 즉, 범주형 변수\n",
    "# 이런경우 인코딩할때는 target 컬럼 제외해야함. 원핫 인코딩의 경우 컬럼 자체가 여러개 만들어짐짐. \n",
    "# 하지만 레이블 인코딩은 가능함. 다만, 0,1,2로 변경한 후 마지막 제출에서 다시 godd, standard, poor로 복원해야함\n",
    "# 다행히 랜덤포레스트는 object더라도 자동으로 인식하여 인코딩 없이도 사용가능함\n",
    "\n",
    "# 데이터 전처리\n",
    "target = train.pop('Credit_Score')\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, pred, average='macro')\n",
    "print('f1:', f1)\n",
    "\n",
    "pred = model.predict(test)\n",
    "submit = pd.DataFrame({'pred':pred})\n",
    "#submit.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 약물 종류 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 데이터 정보(자료형) =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Age          100 non-null    int64  \n",
      " 1   Sex          100 non-null    object \n",
      " 2   BP           100 non-null    object \n",
      " 3   Cholesterol  100 non-null    object \n",
      " 4   Na_to_K      100 non-null    float64\n",
      " 5   Drug         100 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n",
      "\n",
      " ===== train 결측치 수 =====\n",
      "0\n",
      "\n",
      " ===== test 결측치 수 =====\n",
      "0\n",
      "\n",
      " ===== train/test 카테고리별 수 =====\n",
      "Sex            2\n",
      "BP             3\n",
      "Cholesterol    2\n",
      "dtype: int64\n",
      "Sex            2\n",
      "BP             3\n",
      "Cholesterol    2\n",
      "dtype: int64\n",
      "\n",
      " ===== target 빈도 =====\n",
      "DrugY    41\n",
      "drugX    34\n",
      "drugA    13\n",
      "drugB     8\n",
      "drugC     4\n",
      "Name: Drug, dtype: int64\n",
      "\n",
      " f1-macro: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/drug_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch7/drug_test.csv\")\n",
    "\n",
    "# 3. 탐색적 데이터 분석(EDA)\n",
    "print(\"===== 데이터 정보(자료형) =====\")\n",
    "print(train.info())\n",
    "\n",
    "print(\"\\n ===== train 결측치 수 =====\")\n",
    "print(train.isnull().sum().sum())\n",
    "\n",
    "print(\"\\n ===== test 결측치 수 =====\")\n",
    "print(test.isnull().sum().sum())\n",
    "\n",
    "print(\"\\n ===== train/test 카테고리별 수 =====\")\n",
    "print(train[['Sex', 'BP', 'Cholesterol']].nunique())\n",
    "print(test[['Sex', 'BP', 'Cholesterol']].nunique())\n",
    "\n",
    "print(\"\\n ===== target 빈도 =====\")\n",
    "print(train['Drug'].value_counts())\n",
    "\n",
    "\n",
    "# 4. 데이터 전처리\n",
    "# 원핫인코딩\n",
    "target = train.pop('Drug')\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# 5. 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "# 6. 머신러닝 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred = rf.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_val, pred, average='macro')\n",
    "print('\\n f1-macro:', f1)\n",
    "\n",
    "# 7. 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "submit = pd.DataFrame({'pred':pred})\n",
    "submit.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10505.000000</td>\n",
       "      <td>10505.000000</td>\n",
       "      <td>10505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.225536</td>\n",
       "      <td>26.050547</td>\n",
       "      <td>20650.139838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.182264</td>\n",
       "      <td>13.539947</td>\n",
       "      <td>22570.924117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.170000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>42457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.500000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>110936.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     days_left          price\n",
       "count  10505.000000  10505.000000   10505.000000\n",
       "mean      12.225536     26.050547   20650.139838\n",
       "std        7.182264     13.539947   22570.924117\n",
       "min        0.830000      1.000000    1105.000000\n",
       "25%        6.750000     15.000000    4755.000000\n",
       "50%       11.250000     26.000000    7455.000000\n",
       "75%       16.170000     38.000000   42457.000000\n",
       "max       40.500000     49.000000  110936.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_test.csv\")\n",
    "\n",
    "# 학습용 데이터를 이용해 티켓 가격을 예측하는 모델을 만든 후, 평가용 데이턷에 적용해 얻은 값을 csv로 저장\n",
    "# 성능은 RMSE에 따라 채점\n",
    "\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10505, 37) (4502, 37)\n",
      "rmse 4349.574952340415\n"
     ]
    }
   ],
   "source": [
    "# 베이스라인에서 flight는 train과 test의 데이터의 카테고리가 달라 삭제함\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/flight_test.csv\")\n",
    "target = train.pop('price')\n",
    "\n",
    "# 카테고리가 다른 경우 삭제\n",
    "train = train.drop('flight', axis=1)\n",
    "test = test.drop('flight', axis=1)\n",
    "\n",
    "# 원핫인코딩\n",
    "# train=pd.get_dummies(train)\n",
    "# test=pd.get_dummies(test)\n",
    "\n",
    "full = pd.concat([train, test])\n",
    "full_dummies = pd.get_dummies(full)\n",
    "n_train = len(train)\n",
    "train = full_dummies[:n_train]\n",
    "test = full_dummies[n_train:]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error #root이므로 squared를 False\n",
    "result = mean_squared_error(y_val, pred, squared=False)\n",
    "print('rmse', result)\n",
    "\n",
    "pred = model.predict(test)\n",
    "submit = pd.DataFrame({\n",
    "    'pred':pred\n",
    "})\n",
    "#submit.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중고차 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 데이터 크기 =====\n",
      "(6732, 17) (5772, 16)\n",
      "\n",
      " ===== train 데이터 샘플 =====\n",
      "   Price Levy Manufacturer   Model  Prod. year Category Leather interior  \\\n",
      "0  13956  603        LEXUS  RX 450        2015     Jeep              Yes   \n",
      "\n",
      "  Fuel type Engine volume    Mileage  Cylinders Gear box type Drive wheels  \\\n",
      "0    Hybrid           3.5  143619 km        6.0     Automatic          4x4   \n",
      "\n",
      "    Doors       Wheel  Color  Airbags  \n",
      "0  04-May  Left wheel  Black       12  \n",
      "\n",
      " ===== test 데이터 샘플 =====\n",
      "  Levy Manufacturer   Model  Prod. year Category Leather interior Fuel type  \\\n",
      "0  730    SSANGYONG  Actyon        2016     Jeep              Yes    Petrol   \n",
      "\n",
      "  Engine volume   Mileage  Cylinders Gear box type Drive wheels   Doors  \\\n",
      "0           1.6  70940 km        4.0     Automatic        Front  04-May   \n",
      "\n",
      "        Wheel  Color  Airbags  \n",
      "0  Left wheel  Black        4  \n",
      "\n",
      " ===== 데이터 정보(자료형) =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Price             6732 non-null   int64  \n",
      " 1   Levy              6732 non-null   object \n",
      " 2   Manufacturer      6732 non-null   object \n",
      " 3   Model             6732 non-null   object \n",
      " 4   Prod. year        6732 non-null   int64  \n",
      " 5   Category          6732 non-null   object \n",
      " 6   Leather interior  6732 non-null   object \n",
      " 7   Fuel type         6732 non-null   object \n",
      " 8   Engine volume     6732 non-null   object \n",
      " 9   Mileage           6732 non-null   object \n",
      " 10  Cylinders         6732 non-null   float64\n",
      " 11  Gear box type     6732 non-null   object \n",
      " 12  Drive wheels      6732 non-null   object \n",
      " 13  Doors             6732 non-null   object \n",
      " 14  Wheel             6732 non-null   object \n",
      " 15  Color             6732 non-null   object \n",
      " 16  Airbags           6732 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(13)\n",
      "memory usage: 894.2+ KB\n",
      "None\n",
      "\n",
      " ===== train 결측치 수 =====\n",
      "0\n",
      "\n",
      " ===== test 결측치 수 =====\n",
      "0\n",
      "\n",
      " ===== 카테고리 비교 =====\n",
      "Levy \t카테고리 동일하지 않음\n",
      "Manufacturer \t카테고리 동일하지 않음\n",
      "Model \t카테고리 동일하지 않음\n",
      "Category \t카테고리 동일함\n",
      "Leather interior \t카테고리 동일함\n",
      "Fuel type \t카테고리 동일하지 않음\n",
      "Engine volume \t카테고리 동일하지 않음\n",
      "Mileage \t카테고리 동일하지 않음\n",
      "Gear box type \t카테고리 동일함\n",
      "Drive wheels \t카테고리 동일함\n",
      "Doors \t카테고리 동일함\n",
      "Wheel \t카테고리 동일함\n",
      "Color \t카테고리 동일함\n",
      "\n",
      " ===== target 기술 통계 =====\n",
      "count      6732.000000\n",
      "mean      17018.565954\n",
      "std       17497.072247\n",
      "min           3.000000\n",
      "25%        5331.000000\n",
      "50%       13172.000000\n",
      "75%       21953.000000\n",
      "max      228935.000000\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. 문제정의\n",
    "# 평가: RMSLE\n",
    "# target: Price\n",
    "# 최종파일: result.csv(컬럼 1개 pred)\n",
    "\n",
    "# 2. 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "# train = pd.read_csv(\"car_train.csv\")\n",
    "# test = pd.read_csv(\"car_test.csv\")\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/car_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/lovedlim/bigdata_analyst_cert/main/part2/ch8/car_test.csv\")\n",
    "\n",
    "# 3. 탐색적 데이터 분석(EDA)\n",
    "print(\"===== 데이터 크기 =====\")\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "print(\"\\n ===== train 데이터 샘플 =====\")\n",
    "print(train.head(1))\n",
    "\n",
    "print(\"\\n ===== test 데이터 샘플 =====\")\n",
    "print(test.head(1))\n",
    "\n",
    "print(\"\\n ===== 데이터 정보(자료형) =====\")\n",
    "print(train.info())\n",
    "\n",
    "print(\"\\n ===== train 결측치 수 =====\")\n",
    "print(train.isnull().sum().sum())\n",
    "\n",
    "print(\"\\n ===== test 결측치 수 =====\")\n",
    "print(test.isnull().sum().sum())\n",
    "\n",
    "print(\"\\n ===== 카테고리 비교 =====\")\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "for col in cols:\n",
    "    set_train = set(train[col])\n",
    "    set_test= set(test[col])\n",
    "    same = (set_train == set_test)\n",
    "    if same:\n",
    "        print(col, \"\\t카테고리 동일함\")\n",
    "    else:\n",
    "        print(col, \"\\t카테고리 동일하지 않음\")\n",
    "\n",
    "print(\"\\n ===== target 기술 통계 =====\")\n",
    "print(train['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsle: 1.1008952910276844\n"
     ]
    }
   ],
   "source": [
    "target = train.pop('Price')\n",
    "\n",
    "# 레이블 인코딩\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "combined = pd.concat([train,test])\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col])\n",
    "\n",
    "\n",
    "n_train = len(train)\n",
    "train = combined[:n_train]\n",
    "test = combined[n_train:]\n",
    "\n",
    "# 5. 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "# 6. 머신러닝 학습 및 평가\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred = rf.predict(X_val)\n",
    "\n",
    "# RMSLE\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "result = mean_squared_log_error(y_val, pred) ** 0.5\n",
    "print('rmsle:', result)\n",
    "\n",
    "# 7. 예측 및 결과 파일 생성\n",
    "pred = rf.predict(test)\n",
    "submit = pd.DataFrame({'pred':pred})\n",
    "submit.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
